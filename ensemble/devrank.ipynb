{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "557df603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "__author__ = 'Author'\n",
    "__email__ = 'Email'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af65fa",
   "metadata": {},
   "source": [
    "# SemEval 2026 Task 5 - Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "84dcf5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# dependency\n",
    "# built-in\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# third-party\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from xgboost import XGBRanker\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# local - add src/eval to path for importing evaluation functions\n",
    "sys.path.insert(0, str(Path('../src/eval').resolve()))\n",
    "# Import evaluation functions from src/eval/scoring.py\n",
    "import scoring\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b742876",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7c7a896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def load_predictions(filepath):\n",
    "    \"\"\"Load predictions from a JSONL file into a dictionary.\"\"\"\n",
    "    predictions = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            predictions[data['id']] = data['prediction']\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "4d6f7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06797395",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "22c6607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 588 gold labels\n",
      "\n",
      "Gold labels are lists of 5 human ratings (1-5 scale)\n",
      "\n",
      "Example gold labels:\n",
      "  ID 0: [4, 5, 3, 1, 5] (avg=3.60, std=1.67)\n",
      "  ID 1: [3, 3, 4, 4, 4] (avg=3.60, std=0.55)\n",
      "  ID 2: [5, 5, 2, 3, 4] (avg=3.80, std=1.30)\n",
      "  ID 3: [4, 5, 4, 3, 5] (avg=4.20, std=0.84)\n",
      "  ID 4: [1, 5, 4, 4, 1] (avg=3.00, std=1.87)\n"
     ]
    }
   ],
   "source": [
    "# Load gold labels (solution file)\n",
    "SOLUTION_FILE = Path(\"../res/data/dev_solution.jsonl\")\n",
    "\n",
    "gold_labels = {}\n",
    "with open(SOLUTION_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        gold_labels[data['id']] = data['label']\n",
    "\n",
    "print(f\"Loaded {len(gold_labels)} gold labels\")\n",
    "print(f\"\\nGold labels are lists of 5 human ratings (1-5 scale)\")\n",
    "print(f\"\\nExample gold labels:\")\n",
    "for i in range(5):\n",
    "    sample_id = str(i)\n",
    "    print(f\"  ID {sample_id}: {gold_labels[sample_id]} (avg={np.mean(gold_labels[sample_id]):.2f}, std={np.std(gold_labels[sample_id], ddof=1):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a52dc",
   "metadata": {},
   "source": [
    "## System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "cb32e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 prediction files:\n",
      "  - david_v1.jsonl\n",
      "  - david_v2.jsonl\n",
      "  - korean.jsonl\n",
      "  - urdu_v1.jsonl\n",
      "  - urdu_v2.jsonl\n",
      "  - urdu_v3.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Path to individual system outputs\n",
    "RESULTS_DIR = Path(\"./dev\")\n",
    "\n",
    "# Get all jsonl files\n",
    "prediction_files = sorted(RESULTS_DIR.glob(\"*.jsonl\"))\n",
    "print(f\"Found {len(prediction_files)} prediction files:\")\n",
    "for f in prediction_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "59e1d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 588 predictions from david_v1\n",
      "Loaded 588 predictions from david_v2\n",
      "Loaded 588 predictions from korean\n",
      "Loaded 588 predictions from urdu_v1\n",
      "Loaded 588 predictions from urdu_v2\n",
      "Loaded 588 predictions from urdu_v3\n",
      "\n",
      "Predictions DataFrame shape: (588, 6)\n",
      "Number of samples: 588\n",
      "Number of systems: 6\n",
      "\n",
      "Systems: ['david_v1', 'david_v2', 'korean', 'urdu_v1', 'urdu_v2', 'urdu_v3']\n",
      "\n",
      "Sample data types:\n",
      "david_v1      int64\n",
      "david_v2    float64\n",
      "korean      float64\n",
      "urdu_v1       int64\n",
      "urdu_v2       int64\n",
      "urdu_v3       int64\n",
      "dtype: object\n",
      "\n",
      "First 10 predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>david_v1</th>\n",
       "      <th>david_v2</th>\n",
       "      <th>korean</th>\n",
       "      <th>urdu_v1</th>\n",
       "      <th>urdu_v2</th>\n",
       "      <th>urdu_v3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0600</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.9400</td>\n",
       "      <td>2.586742</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.9976</td>\n",
       "      <td>2.647276</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0024</td>\n",
       "      <td>3.392001</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5480</td>\n",
       "      <td>2.816402</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2.4520</td>\n",
       "      <td>3.373284</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5992</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4008</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2.8696</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3.1304</td>\n",
       "      <td>3.450690</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    david_v1  david_v2    korean  urdu_v1  urdu_v2  urdu_v3\n",
       "id                                                         \n",
       "0          4    4.0600  4.360252        4        4        4\n",
       "1          4    1.9400  2.586742        3        2        3\n",
       "2          5    3.9976  2.647276        4        3        4\n",
       "3          5    2.0024  3.392001        4        4        4\n",
       "4          5    3.5480  2.816402        4        4        4\n",
       "5          4    2.4520  3.373284        4        3        4\n",
       "6          4    4.5992  4.360252        2        4        2\n",
       "7          1    1.4008  1.942182        2        3        2\n",
       "8          3    2.8696  1.942182        2        2        2\n",
       "9          3    3.1304  3.450690        4        5        4"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all predictions\n",
    "all_predictions = {}\n",
    "for pred_file in prediction_files:\n",
    "    system_name = pred_file.stem  # filename without extension\n",
    "    all_predictions[system_name] = load_predictions(pred_file)\n",
    "    print(f\"Loaded {len(all_predictions[system_name])} predictions from {system_name}\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "# Each row is a sample, each column is a system's prediction\n",
    "df_predictions = pd.DataFrame(all_predictions)\n",
    "df_predictions.index.name = 'id'\n",
    "\n",
    "print(f\"\\nPredictions DataFrame shape: {df_predictions.shape}\")\n",
    "print(f\"Number of samples: {len(df_predictions)}\")\n",
    "print(f\"Number of systems: {len(df_predictions.columns)}\")\n",
    "print(f\"\\nSystems: {list(df_predictions.columns)}\")\n",
    "print(f\"\\nSample data types:\")\n",
    "print(df_predictions.dtypes)\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "df_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1b49qoanf5i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (588, 11)\n",
      "\n",
      "Columns: ['david_v1', 'david_v2', 'korean', 'urdu_v1', 'urdu_v2', 'urdu_v3', 'gold_labels', 'gold_avg', 'gold_std', 'group_id', 'unique_key']\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>david_v1</th>\n",
       "      <th>david_v2</th>\n",
       "      <th>korean</th>\n",
       "      <th>urdu_v1</th>\n",
       "      <th>urdu_v2</th>\n",
       "      <th>urdu_v3</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>gold_avg</th>\n",
       "      <th>gold_std</th>\n",
       "      <th>group_id</th>\n",
       "      <th>unique_key</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0600</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 5, 3, 1, 5]</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.673320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.9400</td>\n",
       "      <td>2.586742</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 3, 4, 4, 4]</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.9976</td>\n",
       "      <td>2.647276</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 5, 2, 3, 4]</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0024</td>\n",
       "      <td>3.392001</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 5, 4, 3, 5]</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.836660</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5480</td>\n",
       "      <td>2.816402</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 5, 4, 4, 1]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.870829</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2.4520</td>\n",
       "      <td>3.373284</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 3, 4, 1, 3]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5992</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 4, 5, 5, 5]</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4008</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 2, 2, 1]</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2.8696</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 1, 1, 2, 3]</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3.1304</td>\n",
       "      <td>3.450690</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 2, 5, 4, 4]</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    david_v1  david_v2    korean  urdu_v1  urdu_v2  urdu_v3  \\\n",
       "id                                                            \n",
       "0          4    4.0600  4.360252        4        4        4   \n",
       "1          4    1.9400  2.586742        3        2        3   \n",
       "2          5    3.9976  2.647276        4        3        4   \n",
       "3          5    2.0024  3.392001        4        4        4   \n",
       "4          5    3.5480  2.816402        4        4        4   \n",
       "5          4    2.4520  3.373284        4        3        4   \n",
       "6          4    4.5992  4.360252        2        4        2   \n",
       "7          1    1.4008  1.942182        2        3        2   \n",
       "8          3    2.8696  1.942182        2        2        2   \n",
       "9          3    3.1304  3.450690        4        5        4   \n",
       "\n",
       "           gold_labels  gold_avg  gold_std  group_id unique_key  \n",
       "id                                                               \n",
       "0      [4, 5, 3, 1, 5]  3.600000  1.673320         0          0  \n",
       "1      [3, 3, 4, 4, 4]  3.600000  0.547723         0          1  \n",
       "2      [5, 5, 2, 3, 4]  3.800000  1.303840         0          2  \n",
       "3      [4, 5, 4, 3, 5]  4.200000  0.836660         0          3  \n",
       "4      [1, 5, 4, 4, 1]  3.000000  1.870829         0          4  \n",
       "5      [4, 3, 4, 1, 3]  3.000000  1.224745         0          5  \n",
       "6      [4, 4, 5, 5, 5]  4.600000  0.547723         1          6  \n",
       "7   [1, 1, 1, 2, 2, 1]  1.333333  0.516398         1          7  \n",
       "8      [4, 1, 1, 2, 3]  2.200000  1.303840         1          8  \n",
       "9      [4, 2, 5, 4, 4]  3.800000  1.095445         1          9  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a combined DataFrame with predictions and gold labels\n",
    "df_gold = pd.DataFrame({\n",
    "    'gold_labels': gold_labels,\n",
    "    'gold_avg': {k: np.mean(v) for k, v in gold_labels.items()},\n",
    "    'gold_std': {k: np.std(v, ddof=1) for k, v in gold_labels.items()}\n",
    "})\n",
    "\n",
    "# Combine predictions with gold labels\n",
    "df_combined = df_predictions.join(df_gold)\n",
    "\n",
    "\n",
    "df_combined = df_combined.copy()\n",
    "df_combined['group_id'] = np.arange(len(df_combined)) // 6\n",
    "\n",
    "df_combined['unique_key'] = df_combined.index\n",
    "print(f\"Combined DataFrame shape: {df_combined.shape}\")\n",
    "print(f\"\\nColumns: {list(df_combined.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df_combined.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fj1yfb0wqcp",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "a72891f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 588\n",
      "Training samples: 408 (69.4%)\n",
      "Test samples: 180 (30.6%)\n",
      "\n",
      "Training set gold_avg distribution:\n",
      "  Mean: 3.121\n",
      "  Std: 1.185\n",
      "  Min: 1.000\n",
      "  Max: 5.000\n",
      "\n",
      "Test set gold_avg distribution:\n",
      "  Mean: 3.112\n",
      "  Std: 1.194\n",
      "  Min: 1.000\n",
      "  Max: 5.000\n",
      "\n",
      "Training set sample IDs range: 0 to 407\n",
      "Test set sample IDs range: 0 to 179\n"
     ]
    }
   ],
   "source": [
    "# Use stratification based on binned gold_avg to ensure balanced distribution\n",
    "df_combined['gold_bin'] = pd.cut(df_combined['gold_avg'], bins=5, labels=False)\n",
    "\n",
    "group_labels = df_combined.groupby('group_id')['gold_bin'].mean().astype(int)\n",
    "group_labels = group_labels.to_dict()\n",
    "\n",
    "group_ids = df_combined['group_id'].unique()\n",
    "\n",
    "\n",
    "group_labels_for_split = [group_labels[g] for g in group_ids]\n",
    "\n",
    "\n",
    "train_groups, test_groups = train_test_split(\n",
    "    group_ids, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=group_labels_for_split\n",
    ")\n",
    "\n",
    "train_df = df_combined[df_combined['group_id'].isin(train_groups)].reset_index(drop=True)\n",
    "test_df  = df_combined[df_combined['group_id'].isin(test_groups)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total samples: {len(df_combined)}\")\n",
    "print(f\"Training samples: {len(train_df)} ({len(train_df)/len(df_combined)*100:.1f}%)\")\n",
    "print(f\"Test samples: {len(test_df)} ({len(test_df)/len(df_combined)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTraining set gold_avg distribution:\")\n",
    "print(f\"  Mean: {train_df['gold_avg'].mean():.3f}\")\n",
    "print(f\"  Std: {train_df['gold_avg'].std():.3f}\")\n",
    "print(f\"  Min: {train_df['gold_avg'].min():.3f}\")\n",
    "print(f\"  Max: {train_df['gold_avg'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nTest set gold_avg distribution:\")\n",
    "print(f\"  Mean: {test_df['gold_avg'].mean():.3f}\")\n",
    "print(f\"  Std: {test_df['gold_avg'].std():.3f}\")\n",
    "print(f\"  Min: {test_df['gold_avg'].min():.3f}\")\n",
    "print(f\"  Max: {test_df['gold_avg'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nTraining set sample IDs range: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"Test set sample IDs range: {test_df.index.min()} to {test_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "dk6qijpzjlj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (408, 5)\n",
      "y_train shape: (408,)\n",
      "X_test shape: (180, 5)\n",
      "y_test shape: (180,)\n",
      "\n",
      "First few training samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>david_v2</th>\n",
       "      <th>korean</th>\n",
       "      <th>urdu_v1</th>\n",
       "      <th>urdu_v2</th>\n",
       "      <th>urdu_v3</th>\n",
       "      <th>gold_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0600</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.9400</td>\n",
       "      <td>2.586742</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9976</td>\n",
       "      <td>2.647276</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0024</td>\n",
       "      <td>3.392001</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5480</td>\n",
       "      <td>2.816402</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   david_v2    korean  urdu_v1  urdu_v2  urdu_v3  gold_avg\n",
       "0    4.0600  4.360252        4        4        4       3.6\n",
       "1    1.9400  2.586742        3        2        3       3.6\n",
       "2    3.9976  2.647276        4        3        4       3.8\n",
       "3    2.0024  3.392001        4        4        4       4.2\n",
       "4    3.5480  2.816402        4        4        4       3.0"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training and test sets\n",
    "# X = system predictions (features), y = gold average (target)\n",
    "\n",
    "SYSTEMS = ['david_v2', 'korean', 'urdu_v1', 'urdu_v2', 'urdu_v3']\n",
    "\n",
    "OBJECTIVE_FUNCTION = \"rank:pairwise\"\n",
    "\n",
    "X_train = train_df[SYSTEMS.copy()]\n",
    "# X_train = train_df[['david_v1', 'david_v2', 'korean']]\n",
    "y_train = train_df['gold_avg']\n",
    "\n",
    "X_test = test_df[SYSTEMS.copy()]\n",
    "# X_test = test_df[['david_v1', 'david_v2', 'korean']]\n",
    "y_test = test_df['gold_avg']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nFirst few training samples:\")\n",
    "pd.concat([X_train.head(5), y_train.head(5)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab584e1",
   "metadata": {},
   "source": [
    "# System Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "401ea1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions following the structure of src/eval/scoring.py\n",
    "def evaluate_predictions_array(y_pred, y_true_labels):\n",
    "    \"\"\"\n",
    "    Evaluate predictions using the same logic as scoring.py\n",
    "    \n",
    "    Args:\n",
    "        y_pred: array of predictions\n",
    "        y_true_labels: list of gold label lists (5 ratings each)\n",
    "    \n",
    "    Returns:\n",
    "        dict with spearman and accuracy scores\n",
    "    \"\"\"\n",
    "    # Build prediction and gold lists (same structure as scoring.py)\n",
    "    pred_list = list(y_pred)\n",
    "    gold_list = [scoring.get_average(labels) for labels in y_true_labels]\n",
    "    \n",
    "    # Calculate Spearman correlation (same as scoring.py)\n",
    "    corr, p_value = spearmanr(pred_list, gold_list)\n",
    "    \n",
    "    # Calculate accuracy within SD (same logic as scoring.py)\n",
    "    correct_guesses = 0\n",
    "    wrong_guesses = 0\n",
    "    \n",
    "    for pred, labels in zip(pred_list, y_true_labels):\n",
    "        if scoring.is_within_standard_deviation(pred, labels):\n",
    "            correct_guesses += 1\n",
    "        else:\n",
    "            wrong_guesses += 1\n",
    "    \n",
    "    accuracy = correct_guesses / (correct_guesses + wrong_guesses)\n",
    "    \n",
    "    return {\n",
    "        'spearman': corr,\n",
    "        'p_value': p_value,\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct_guesses,\n",
    "        'total': correct_guesses + wrong_guesses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "4675dd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Individual System Performance on Test Set (30%)\n",
      "================================================================================\n",
      "System              Spearman     Accuracy   Correct/Total\n",
      "--------------------------------------------------------------------------------\n",
      "david_v2            71.2139%     75.0000%     135/180    \n",
      "korean              83.3728%     91.6667%     165/180    \n",
      "urdu_v1             47.8694%     73.8889%     133/180    \n",
      "urdu_v2             54.2010%     68.3333%     123/180    \n",
      "urdu_v3             46.9711%     72.7778%     131/180    \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each system on test set\n",
    "print(\"=\" * 80)\n",
    "print(\"Individual System Performance on Test Set (30%)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'System':<15} {'Spearman':>12} {'Accuracy':>12} {'Correct/Total':>15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "system_results = {}\n",
    "test_gold_labels = test_df['gold_labels'].tolist()\n",
    "\n",
    "for system in SYSTEMS.copy():\n",
    "# for system in ['david_v1', 'david_v2', 'korean']:\n",
    "    # Get predictions from X_test\n",
    "    y_pred = X_test[system].values\n",
    "    \n",
    "    # Evaluate using official logic\n",
    "    scores = evaluate_predictions_array(y_pred, test_gold_labels)\n",
    "    system_results[system] = scores\n",
    "    \n",
    "    print(f\"{system:<15} {scores['spearman']:>12.4%} {scores['accuracy']:>12.4%} \"\n",
    "          f\"{scores['correct']:>7}/{scores['total']:<7}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qi5dte9168s",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76405638",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "9699fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Mean Ensemble: y_pred = (1/N) * sum(y_i)\n",
    "y_pred_mean = X_test.mean(axis=1).values\n",
    "\n",
    "# Evaluate float version\n",
    "scores_mean_float = evaluate_predictions_array(y_pred_mean, test_gold_labels)\n",
    "# print(f\"Mean (float) - Spearman: {scores_mean_float['spearman']:.4%}, Accuracy: {scores_mean_float['accuracy']:.4%}\")\n",
    "\n",
    "# Evaluate integer version\n",
    "y_pred_mean_int = y_pred_mean.round().clip(1, 5).astype(int)\n",
    "scores_mean_int = evaluate_predictions_array(y_pred_mean_int, test_gold_labels)\n",
    "# print(f\"Mean (int)   - Spearman: {scores_mean_int['spearman']:.4%}, Accuracy: {scores_mean_int['accuracy']:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21923b15",
   "metadata": {},
   "source": [
    "## Weighted Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "6e142616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Mean: weights learned from train set (70%) based on Spearman performance\n",
    "train_gold_labels = train_df['gold_labels'].tolist()\n",
    "\n",
    "# Calculate weights based on train set performance (Spearman correlation)\n",
    "weights = []\n",
    "for system in SYSTEMS.copy():\n",
    "# for system in ['david_v1', 'david_v2', 'korean']:\n",
    "    y_pred_train = X_train[system].values\n",
    "    scores_train = evaluate_predictions_array(y_pred_train, train_gold_labels)\n",
    "    weights.append(scores_train['spearman'])\n",
    "\n",
    "# Convert to numpy array and normalize to sum to 1\n",
    "weights = np.array(weights)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Apply weighted average on test set\n",
    "y_pred_weighted = (X_test.values * weights).sum(axis=1)\n",
    "\n",
    "# Evaluate float version\n",
    "scores_weighted_float = evaluate_predictions_array(y_pred_weighted, test_gold_labels)\n",
    "# print(f\"Weighted Mean (float) - Spearman: {scores_weighted_float['spearman']:.4%}, Accuracy: {scores_weighted_float['accuracy']:.4%}\")\n",
    "\n",
    "# Evaluate integer version\n",
    "y_pred_weighted_int = y_pred_weighted.round().clip(1, 5).astype(int)\n",
    "scores_weighted_int = evaluate_predictions_array(y_pred_weighted_int, test_gold_labels)\n",
    "# print(f\"Weighted Mean (int)   - Spearman: {scores_weighted_int['spearman']:.4%}, Accuracy: {scores_weighted_int['accuracy']:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b802c",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "b12elmi6l38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Voting: most common rounded prediction across systems\n",
    "# Round predictions to integers (1-5 range)\n",
    "X_test_rounded = X_test.round().clip(1, 5).astype(int)\n",
    "\n",
    "# Get mode (most frequent value) for each row\n",
    "y_pred_majority = stats.mode(X_test_rounded, axis=1, keepdims=False)[0]\n",
    "\n",
    "# Evaluate\n",
    "scores_majority = evaluate_predictions_array(y_pred_majority, test_gold_labels)\n",
    "# print(f\"Majority Voting - Spearman: {scores_majority['spearman']:.4%}, Accuracy: {scores_majority['accuracy']:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp9my6eewls",
   "metadata": {},
   "source": [
    "## Weighted Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "1f81163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Majority Voting: weighted voting using performance-based weights\n",
    "# Round test predictions to integers\n",
    "X_test_rounded = X_test.round().clip(1, 5).astype(int)\n",
    "\n",
    "# Use weights learned earlier (from Weighted Mean)\n",
    "y_pred_weighted_vote = []\n",
    "for idx in range(len(X_test_rounded)):\n",
    "    # Get predictions for this sample\n",
    "    votes = X_test_rounded.iloc[idx].values\n",
    "    \n",
    "    # Count weighted votes for each class (1-5)\n",
    "    vote_counts = {}\n",
    "    for vote, weight in zip(votes, weights):\n",
    "        vote_counts[vote] = vote_counts.get(vote, 0) + weight\n",
    "    \n",
    "    # Select class with highest weighted vote\n",
    "    winner = max(vote_counts.items(), key=lambda x: x[1])[0]\n",
    "    y_pred_weighted_vote.append(winner)\n",
    "\n",
    "y_pred_weighted_vote = np.array(y_pred_weighted_vote)\n",
    "\n",
    "# Evaluate\n",
    "scores_weighted_vote = evaluate_predictions_array(y_pred_weighted_vote, test_gold_labels)\n",
    "# print(f\"Weighted Majority Voting - Spearman: {scores_weighted_vote['spearman']:.4%}, Accuracy: {scores_weighted_vote['accuracy']:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4abc10",
   "metadata": {},
   "source": [
    "## Linear Stacking (Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "c008e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (float) - Spearman: 85.2726%, Accuracy: 93.3333%\n"
     ]
    }
   ],
   "source": [
    "# Linear Stacking: learn weights via Ridge Regression on train set\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Evaluate float version\n",
    "scores_ridge_float = evaluate_predictions_array(y_pred_ridge, test_gold_labels)\n",
    "print(f\"Ridge (float) - Spearman: {scores_ridge_float['spearman']:.4%}, Accuracy: {scores_ridge_float['accuracy']:.4%}\")\n",
    "\n",
    "# Evaluate integer version\n",
    "y_pred_ridge_int = y_pred_ridge.round().clip(1, 5).astype(int)\n",
    "scores_ridge_int = evaluate_predictions_array(y_pred_ridge_int, test_gold_labels)\n",
    "# print(f\"Ridge (int)   - Spearman: {scores_ridge_int['spearman']:.4%}, Accuracy: {scores_ridge_int['accuracy']:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "ae292105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "david_v2             +0.1343\n",
      "korean               +0.9156\n",
      "urdu_v1              +0.1221\n",
      "urdu_v2              +0.0779\n",
      "urdu_v3              -0.0763\n"
     ]
    }
   ],
   "source": [
    "# Inspect Ridge Weights\n",
    "coef = ridge.coef_\n",
    "for name, w in zip(X_train.columns, coef):\n",
    "    print(f\"{name:20s} {w:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "1bc72765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 prediction files:\n",
      "  - david_v1.jsonl\n",
      "  - david_v2.jsonl\n",
      "  - korean.jsonl\n",
      "  - urdu_v2.jsonl\n",
      "  - urdu_v3.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Path to individual system outputs\n",
    "RESULTS_DIR = Path(\"./test\")\n",
    "\n",
    "# Get all jsonl files\n",
    "prediction_files_test = sorted(RESULTS_DIR.glob(\"*.jsonl\"))\n",
    "print(f\"Found {len(prediction_files_test)} prediction files:\")\n",
    "for f in prediction_files_test:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "4b33857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 930 predictions from david_v1\n",
      "Loaded 930 predictions from david_v2\n",
      "Loaded 930 predictions from korean\n",
      "Loaded 930 predictions from urdu_v2\n",
      "Loaded 930 predictions from urdu_v3\n",
      "\n",
      "Predictions DataFrame shape: (930, 5)\n",
      "Number of samples: 930\n",
      "Number of systems: 5\n",
      "\n",
      "Systems: ['david_v1', 'david_v2', 'korean', 'urdu_v2', 'urdu_v3']\n",
      "\n",
      "Sample data types:\n",
      "david_v1      int64\n",
      "david_v2    float64\n",
      "korean      float64\n",
      "urdu_v2       int64\n",
      "urdu_v3       int64\n",
      "dtype: object\n",
      "\n",
      "First 10 predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>david_v1</th>\n",
       "      <th>david_v2</th>\n",
       "      <th>korean</th>\n",
       "      <th>urdu_v2</th>\n",
       "      <th>urdu_v3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.8780</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.1220</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6828</td>\n",
       "      <td>4.360252</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.3172</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.7560</td>\n",
       "      <td>4.397248</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1.2440</td>\n",
       "      <td>2.051280</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2.4116</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5884</td>\n",
       "      <td>4.033600</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2.7420</td>\n",
       "      <td>1.942182</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3.2580</td>\n",
       "      <td>4.033600</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    david_v1  david_v2    korean  urdu_v2  urdu_v3\n",
       "id                                                \n",
       "0          4    4.8780  4.360252        5        4\n",
       "1          3    1.1220  1.942182        4        3\n",
       "2          4    4.6828  4.360252        4        4\n",
       "3          4    1.3172  1.942182        3        3\n",
       "4          5    4.7560  4.397248        4        4\n",
       "5          3    1.2440  2.051280        4        3\n",
       "6          5    2.4116  1.942182        3        3\n",
       "7          3    3.5884  4.033600        3        4\n",
       "8          2    2.7420  1.942182        3        3\n",
       "9          3    3.2580  4.033600        2        4"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all predictions\n",
    "all_test_predictions = {}\n",
    "for pred_file in prediction_files_test:\n",
    "    system_name = pred_file.stem  # filename without extension\n",
    "    all_test_predictions[system_name] = load_predictions(pred_file)\n",
    "    print(f\"Loaded {len(all_test_predictions[system_name])} predictions from {system_name}\")\n",
    "# Convert to DataFrame for easier manipulation\n",
    "# Each row is a sample, each column is a system's prediction\n",
    "df_predictions_test = pd.DataFrame(all_test_predictions)\n",
    "df_predictions_test.index.name = 'id'\n",
    "\n",
    "print(f\"\\nPredictions DataFrame shape: {df_predictions_test.shape}\")\n",
    "print(f\"Number of samples: {len(df_predictions_test)}\")\n",
    "print(f\"Number of systems: {len(df_predictions_test.columns)}\")\n",
    "print(f\"\\nSystems: {list(df_predictions_test.columns)}\")\n",
    "print(f\"\\nSample data types:\")\n",
    "print(df_predictions_test.dtypes)\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "df_predictions_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fff7f503",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['urdu_v1'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[569], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m str_for_part_of_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SYSTEMS)\n\u001b[1;32m      2\u001b[0m addr_saving \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_for_part_of_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ridge_testset_predictions.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m X_test_set_real \u001b[38;5;241m=\u001b[39m \u001b[43mdf_predictions_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSYSTEMS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred_ridge_test_set \u001b[38;5;241m=\u001b[39m ridge\u001b[38;5;241m.\u001b[39mpredict(X_test_set_real)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred_ridge_test_set))\n",
      "File \u001b[0;32m~/.conda/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['urdu_v1'] not in index\""
     ]
    }
   ],
   "source": [
    "str_for_part_of_filename = '_'.join(SYSTEMS)\n",
    "addr_saving = f'ensemble_{str_for_part_of_filename}_ridge_testset_predictions.jsonl'\n",
    "\n",
    "X_test_set_real = df_predictions_test[SYSTEMS.copy()]\n",
    "\n",
    "y_pred_ridge_test_set = ridge.predict(X_test_set_real)\n",
    "\n",
    "print(len(y_pred_ridge_test_set))\n",
    "\n",
    "a = 0\n",
    "\n",
    "with open(addr_saving, 'w', encoding='utf-8') as f:\n",
    "    for val in y_pred_ridge_test_set:\n",
    "        f.write('{\"id\": \"' + str(a) + '\", \"prediction\": ' + str(val) + '}\\n')\n",
    "        a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63927e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_these_extremes(arr, low, upp):\n",
    "    \"\"\"Scale array values to be within the specified extremes.\"\"\"\n",
    "    arr_scaled = (arr - arr.min()) / (arr.max() - arr.min()) * (upp - low) + low\n",
    "    return arr_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156pqmx8rme",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    test_gold_labels,\n",
    "    low,\n",
    "    upp,\n",
    "    *,\n",
    "    n_estimators=500,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.05,\n",
    "    min_child_weight=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1.0,     # L1\n",
    "    reg_lambda=10.0,   # L2\n",
    "    random_state=42,\n",
    "):\n",
    "    \n",
    "    group_train_big = [len(X_train)]\n",
    "    \n",
    "    group_train_2 = [2] * (len(y_train) // 2)\n",
    "\n",
    "   \n",
    "    group_train_6 = [6] * (len(y_train) // 6)\n",
    "    \n",
    "\n",
    "    group_train_12 = [12] * (len(y_train) // 12)\n",
    "\n",
    "    xgb = XGBRanker(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    learning_rate=learning_rate,\n",
    "    min_child_weight=min_child_weight,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    reg_alpha=reg_alpha,\n",
    "    reg_lambda=reg_lambda,\n",
    "    objective=OBJECTIVE_FUNCTION,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "    xgb.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    group=group_train_6,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "    # Predict\n",
    "    y_pred = scale_to_these_extremes(xgb.predict(X_test), low, upp)\n",
    "\n",
    "    # Float eval\n",
    "    scores_float = evaluate_predictions_array(y_pred, test_gold_labels)\n",
    "\n",
    "    # Int eval\n",
    "    # y_pred_int = y_pred.round().clip(1, 5).astype(int)\n",
    "    # scores_int = evaluate_predictions_array(y_pred_int, test_gold_labels)\n",
    "\n",
    "    return scores_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64857a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "depth=1 lr=0.1 n=200 | Spearman=84.1200% Acc=88.8889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=1 lr=0.05 n=400 | Spearman=84.3027% Acc=87.7778%\n",
      "depth=1 lr=0.02 n=800 | Spearman=83.9374% Acc=86.6667%\n",
      "\n",
      "depth=2 lr=0.1 n=200 | Spearman=82.6734% Acc=86.1111%\n",
      "depth=2 lr=0.05 n=400 | Spearman=83.0838% Acc=86.6667%\n",
      "depth=2 lr=0.02 n=800 | Spearman=83.2871% Acc=87.7778%\n",
      "\n",
      "depth=3 lr=0.1 n=200 | Spearman=81.5956% Acc=85.5556%\n",
      "depth=3 lr=0.05 n=400 | Spearman=81.4504% Acc=85.0000%\n",
      "depth=3 lr=0.02 n=800 | Spearman=81.5551% Acc=85.5556%\n"
     ]
    }
   ],
   "source": [
    "depths = [1, 2, 3]\n",
    "\n",
    "configs = [\n",
    "    dict(learning_rate=0.1,  n_estimators=200, low=1, upp=5),\n",
    "    dict(learning_rate=0.05, n_estimators=400, low=1, upp=5),\n",
    "    dict(learning_rate=0.02, n_estimators=800, low=1, upp=5),\n",
    "]\n",
    "\n",
    "\n",
    "regularizers = [\n",
    "    dict(reg_alpha=0.0, reg_lambda=1.0),\n",
    "    dict(reg_alpha=1.0, reg_lambda=10.0),\n",
    "    dict(reg_alpha=10.0, reg_lambda=50.0),\n",
    "]\n",
    "\n",
    "for depth in [1, 2, 3]:\n",
    "    print()\n",
    "    for cfg in configs:\n",
    "        scores_float = train_eval_xgb(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            test_gold_labels,\n",
    "            max_depth=depth,\n",
    "            **cfg\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"depth={depth} lr={cfg['learning_rate']} n={cfg['n_estimators']} | \"\n",
    "            f\"Spearman={scores_float['spearman']:.4%} \"\n",
    "            f\"Acc={scores_float['accuracy']:.4%}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "9350302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost depth=1 (float) - Spearman: 85.3826%, Accuracy: 89.4444%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with competition-validated settings\n",
    "\n",
    "if OBJECTIVE_FUNCTION.startswith(\"rank:\") :\n",
    " xgb = XGBRanker(\n",
    "    n_estimators=400,          # matched to lr=0.1\n",
    "    max_depth=1,               # CRITICAL: best Spearman\n",
    "    learning_rate=0.05,\n",
    "    min_child_weight=50,       # strong regularization\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1.0,             # L1 regularization\n",
    "    reg_lambda=10.0,           # L2 regularization\n",
    "    objective=OBJECTIVE_FUNCTION,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "else:\n",
    " assert False\n",
    "\n",
    "\n",
    "\n",
    "group_test_6 = [6] * (len(y_train) // 6)\n",
    "    \n",
    "    \n",
    "# Train on training set\n",
    "xgb.fit(X_train, y_train, group=group_test_6)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_xgb = scale_to_these_extremes(xgb.predict(X_test), 1, 5)\n",
    "\n",
    "# Evaluate float version\n",
    "scores_xgb_float = evaluate_predictions_array(y_pred_xgb, test_gold_labels)\n",
    "print(\n",
    "    f\"XGBoost depth=1 (float) - \"\n",
    "    f\"Spearman: {scores_xgb_float['spearman']:.4%}, \"\n",
    "    f\"Accuracy: {scores_xgb_float['accuracy']:.4%}\"\n",
    ")\n",
    "\n",
    "# Evaluate integer version\n",
    "# y_pred_xgb_int = y_pred_xgb.round().clip(1, 5).astype(int)\n",
    "# scores_xgb_int = evaluate_predictions_array(y_pred_xgb_int, test_gold_labels)\n",
    "# print(\n",
    "#     f\"XGBoost depth=1 (int)   - \"\n",
    "#     f\"Spearman: {scores_xgb_int['spearman']:.4%}, \"\n",
    "#     f\"Accuracy: {scores_xgb_int['accuracy']:.4%}\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
